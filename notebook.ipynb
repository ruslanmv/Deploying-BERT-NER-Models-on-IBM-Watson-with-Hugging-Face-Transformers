
{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Deploying BERT NER Models on IBM Watson Machine Learning with Hugging Face Transformers\n",
       "\n",
       "This notebook contains steps and code to demonstrate the deployment of a BERT NER model using Hugging Face transformers on IBM Watson Machine Learning (WML) service. It includes commands for setting up the environment, creating model definitions, training the model, persisting the trained model, deploying, and scoring the model."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Learning Goals\n",
       "\n",
       "- Working with Watson Machine Learning service.\n",
       "- Training BERT NER models using Hugging Face.\n",
       "- Saving trained models in Watson Machine Learning repository.\n",
       "- Online deployment and scoring of trained model."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Contents\n",
       "\n",
       "1. [Set up the environment](#setup)\n",
       "2. [Create model definition](#model_def)\n",
       "3. [Train model](#training)\n",
       "4. [Persist trained model](#persist)\n",
       "5. [Deploy and Score](#deploy)\n",
       "6. [Clean up](#clean)\n",
       "7. [Summary and next steps](#summary)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "<a id=\"setup\"></a>\n",
       "## 1. Set up the environment\n",
       "\n",
       "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
       "\n",
       "- Contact with your Cloud Pack for Data administrator and ask them for your account credentials"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Install and import the `ibm-watsonx-ai` and dependencies"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "!pip install wget | tail -n 1\n",
       "!pip install -U ibm-watsonx-ai | tail -n 1\n",
       "!pip install transformers | tail -n 1\n",
       "!pip install torch | tail -n 1"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Connection to WML\n",
       "\n",
       "Authenticate the Watson Machine Learning service on IBM Cloud Pack for Data. You need to provide platform `url`, your `username`, and `api_key`."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from ibm_watsonx_ai import Credentials, APIClient\n",
       "\n",
       "username = 'PASTE YOUR USERNAME HERE'\n",
       "api_key = 'PASTE YOUR API_KEY HERE'\n",
       "url = 'PASTE THE PLATFORM URL HERE'\n",
       "\n",
       "credentials = Credentials(\n",
       "    username=username,\n",
       "    api_key=api_key,\n",
       "    url=url,\n",
       "    instance_id=\"openshift\",\n",
       "    version=\"5.0\"\n",
       ")\n",
       "\n",
       "client = APIClient(credentials)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Working with spaces\n",
       "\n",
       "First of all, you need to create a space that will be used for your work. If you do not have space already created, you can use `{PLATFORM_URL}/ml-runtime/spaces?context=icp4data` to create one.\n",
       "\n",
       "- Click New Deployment Space\n",
       "- Create an empty space\n",
       "- Go to space `Settings` tab\n",
       "- Copy `space_id` and paste it below"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "space_id = 'PASTE YOUR SPACE ID HERE'"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "You can use `list` method to print all existing spaces."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "client.spaces.list(limit=10)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "To be able to interact with all resources available in Watson Machine Learning, you need to set **space** which you will be using."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "client.set.default_space(space_id)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "<a id=\"model_def\"></a>\n",
       "## 2. Create model definition"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2.1 Prepare model definition metadata"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "model_definition_metadata = {\n",
       "    client.model_definitions.ConfigurationMetaNames.NAME: \"BERT NER Model\",\n",
       "    client.model_definitions.ConfigurationMetaNames.DESCRIPTION: \"BERT model for Named Entity Recognition\",\n",
       "    client.model_definitions.ConfigurationMetaNames.COMMAND: \"ner_train.py\",\n",
       "    client.model_definitions.ConfigurationMetaNames.PLATFORM: {\"name\": \"python\", \"versions\": [\"3.11\"]},\n",
       "    client.model_definitions.ConfigurationMetaNames.VERSION: \"1.0\",\n",
       "    client.model_definitions.ConfigurationMetaNames.SPACE_UID: space_id\n",
       "}"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2.2  Get sample model definition content file"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import wget, os\n",
       "\n",
       "filename = 'bert-ner-model.zip'\n",
       "\n",
       "if not os.path.isfile(filename):\n",
       "    filename = wget.download('URL_TO_YOUR_ZIP_FILE_CONTAINING_MODEL_DEFINITION')\n",
       "\n",
       "!unzip -oqd . bert-ner-model.zip"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2.3  Publish model definition"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "definition_details = client.model_definitions.store(filename, model_definition_metadata)\n",
       "model_definition_id = client.model_definitions.get_id(definition_details)\n",
       "print(model_definition_id)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### List models definitions"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "client.model_definitions.list(limit=5)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "<a id=\"training\"></a>\n",
       "## 3. Train model"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### **Note**: Ensure that training data is saved in a folder where Watson Machine Learning Accelerator is installed."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.1 Prepare training metadata"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "training_metadata = {\n",
       "    client.training.ConfigurationMetaNames.NAME: \"BERT NER Training\",\n",
       "    client.training.ConfigurationMetaNames.DESCRIPTION: \"Training BERT model for Named Entity Recognition\",\n",
       "    client.training.ConfigurationMetaNames.TRAINING_RESULTS_REFERENCE: {\n",
       "        \"name\": \"NER results\",\n",
       "        \"connection\": {},\n",
       "        \"location\": {\"path\": f\"spaces/{space_id}/assets/experiment\"},\n",
       "        \"type\": \"fs\"\n",
       "    },\n",
       "    client.training.ConfigurationMetaNames.MODEL_DEFINITION: {\n",
       "        \"id\": model_definition_id,\n",
       "        \"hardware_spec\": {\"name\": \"K80\", \"nodes\": 1},\n",
       "        \"software_spec\": {\"name\": \"pytorch-onnx_rt24.1-py3.11\"}\n",
       "    },\n",
       "    client.training.ConfigurationMetaNames.TRAINING_DATA_REFERENCES: [\n",
       "        {\n",
       "            \"name\": \"training_input_data\",\n",
       "            \"type\": \"fs\",\n",
       "            \"connection\": {},\n",
       "            \"location\": {\"path\": \"bert-ner-dataset\"},\n",
       "            \"schema\": {\"id\": \"idmlp_schema\", \"fields\": [{\"name\": \"text\", \"type\": \"string\"}]}\n",
       "        }\n",
       "    ]\n",
       "}"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.2 Train the model in the background"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "training = client.training.run(training_metadata)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.3 Get training id and status"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "training_id = client.training.get_id(training)\n",
       "print(training_id)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "client.training.get_status(training_id)['state']"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.4 Get training details"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import json\n",
       "\n",
       "training_details = client.training.get_details(training_id)\n",
       "print(json.dumps(training_details, indent=2))"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### List trainings"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "client.training.list(limit=5)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "<a id=\"persist\"></a>\n",
       "## 4. Persist trained model"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 4.1 Publish model"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "software_spec_id = client.software_specifications.get_id_by_name('pytorch-onnx_rt24.1-py3.11')\n",
       "\n",
       "model_meta_props = {\n",
       "    client.repository.ModelMetaNames.NAME: \"BERT NER Model\",\n",
       "    client.repository.ModelMetaNames.TYPE: \"pytorch-onnx_2.1\",\n",
       "    client.repository.ModelMetaNames.SOFTWARE_SPEC_ID: software_spec_id\n",
       "}\n",
       "\n",
       "published_model_details = client.repository.store_model(training_id, meta_props=model_meta_props)\n",
       "model_id = client.repository.get_model_id(published_model_details)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 4.2 Get model details"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "model_details = client.repository.get_details(model_id)\n",
       "print(json.dumps(model_details, indent=2))"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### List stored models"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "client.repository.list_models(limit=5)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "<a id=\"deploy\"></a>\n",
       "## 5. Deploy and score"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 5.1 Create online deployment for published model"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "deployment = client.deployments.create(\n",
       "    model_id, meta_props={\n",
       "        client.deployments.ConfigurationMetaNames.NAME: \"BERT NER Deployment\",\n",
       "        client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
       "    }\n",
       ")\n",
       "\n",
       "scoring_url = client.deployments.get_scoring_href(deployment)\n",
       "deployment_id = client.deployments.get_id(deployment)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 5.2 Get deployments details"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "deployments_details = client.deployments.get_details(deployment_id)\n",
       "print(json.dumps(deployments_details, indent=2))"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 5.3 Score deployed model"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "Prepare sample scoring data:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from transformers import pipeline\n",
       "\n",
       "# Load pre-trained model and tokenizer\n",
       "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
       "\n",
       "# Sample text for testing\n",
       "test_text = \"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, therefore very close to the Manhattan Bridge.\"\n",
       "\n",
       "# Get NER predictions\n",
       "ner_results = ner_pipeline(test_text)\n",
       "print(ner_results)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "<a id=\"clean\"></a>\n",
       "## 6. Clean up"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "If you want to clean up all created assets:\n",
       "- experiments\n",
       "- trainings\n",
       "- pipelines\n",
       "- model definitions\n",
       "- models\n",
       "- functions\n",
       "- deployments\n",
       "\n",
       "please follow this sample [notebook](https://github.com/IBM/watson-machine-learning-samples/blob/master/cpd5.0/notebooks/python_sdk/instance-management/Machine%20Learning%20artifacts%20management.ipynb)."
      ]
     },
     {
       "cell_type": "markdown",
       "metadata": {},
       "source": [
        "<a id=\"summary\"></a>\n",
        "## 7. Summary and next steps"
       ]
    },
    {
       "cell_type": "markdown",
       "metadata": {},
       "source": [
        "You have successfully deployed a BERT NER model using Hugging Face transformers on IBM Watson Machine Learning. You learned how to set up the environment, create model definitions, train the model, persist the trained model, and deploy and score the model. \n\n",
        "For more information, check out the [Online Documentation](https://ibm.github.io/watsonx-ai-python-sdk/samples.html) for more samples, tutorials, and guidance on using IBM Watson Machine Learning with Hugging Face models. \n\n",
        "### Next Steps\n",
        "1. Experiment with fine-tuning the BERT NER model on a custom dataset.\n",
        "2. Explore deploying other transformer models available on Hugging Face.\n",
        "3. Integrate the deployed model into an application for real-world usage."
       ]
    }]}
    